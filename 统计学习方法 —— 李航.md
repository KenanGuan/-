# 统计学习方法——学习记录

[TOC]

### 1. 统计学习方法概论

##### 1.1 统计学习三要素： 

模型 + 策略（优化函数/损失函数） + 方法（算法）

##### 1. 2 学习重点（Content）

一、监督学习

* 感知机

* KNN

* 朴素贝叶斯

* 决策树

* Logistic 回归 / 最大熵模型

* SVM支持向量机

* Boosting方法

* EM算法及其推广

* 隐马尔可夫模型

* 条件随机场

  

二、无监督学习

* 聚类方法

* 奇异值分解

* 主成分分析

* 潜在语义分析

* 概率潜在语义分析

* 马尔可夫链模特卡洛法

* 潜在狄利克雷分配

* PageRank算法

  

### 2. 感知机

##### 2. 1模型：

![Screenshot 2022-02-13 at 5.45.35 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 5.45.35 PM.png)



感知机的目标是求的一个平面，使得数据集被尽可能大的划分正确。

##### 2.2 策略（损失函数定义）

![Screenshot 2022-02-13 at 5.49.28 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 5.49.28 PM.png)，其中
$$
M为误分类点的集合, X \in R^n, Y \in \{-1, 1\}
$$


##### 2.3算法（原始形式)

![Screenshot 2022-02-13 at 6.40.05 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 6.40.05 PM.png)

我们可以证明，当数据集线性可分时，感知机算法收敛，且在训练集上误分类次数K满足不等式（上界）：

![Screenshot 2022-02-13 at 6.42.21 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 6.42.21 PM.png)

##### 2.4 感知机算法对偶形式

![Screenshot 2022-02-13 at 6.54.00 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 6.54.00 PM.png)



对偶形式中，训练实例仅以**内积**的形式出现，为了方便可以预先计算Gram矩阵：

![Screenshot 2022-02-13 at 6.55.55 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 6.55.55 PM.png)

每次更新参数
$$
\alpha_i \leftarrow \alpha_i + \eta \\
\beta \leftarrow \beta + \eta y_i
$$


##### 2.5 感知机代码实现（Python） 

```python
# 感知机原始形式实现
class Perceptron:
    def __init__(self, lr=1.0):
        # 初始化参数
        self.w = None
        self.b = 0 
        self.lr = lr
    
    def sign(self, x):
        return np.dot(x, self.w) + self.b
    
    def fit(self, X, y): 
        self.w = np.zeros(len(X[0]), dtype=np.float32)
        stop_flag = False
        while not stop_flag:
            wrong_cnt = 0
            for i in range(len(X)):
                if y[i] * self.sign(X[i]) <= 0:
                    self.w += self.lr * np.dot(y[i], X[i])
                    self.b += self.lr * y[i]
                    wrong_cnt += 1
            if not wrong_cnt:
                stop_flag = True
                
    def predict(self, X):
        labels = np.dot(X, self.w) + self.b
        labels = np.array([1 if i >= 0 else -1 for i in labels])
        return labels
      
# 构建模型
model = Perceptron()
model.fit(X, y)

# 可视化分类结果
x_points = np.linspace(4, 7, 20)
y_ = -(model.w[0] * x_points + model.b) / model.w[1] # 分类平面 WX + b = 0
plt.plot(x_points, y_)
plt.plot(data[:50, 0], data[:50, 1],  'bo', c='r', label='0')
plt.plot(data[50:100, 0], data[50:100, 1], 'bo', c='b', label='1')
plt.xlabel('sepal length')
plt.ylabel('sepal width')
plt.legend()
```

![Screenshot 2022-02-13 at 7.51.10 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 7.51.10 PM.png)



```python
# 感知机对偶形式实现
class Perceptron:
    def __init__(self, lr=1.0):
        self.a = None
        self.b = 0
        self.lr = lr
        self.Gram = None
    
    def sign(self, y, i):
        return np.dot(self.a * y, self.Gram[i]) + self.b
    
    def fit(self, Gram, y):
        self.Gram = Gram
        # 初始化参数 alpha
        self.a = np.zeros(len(y), dtype=np.float32)
                
        # Start Training
        stop_flag = False
        while not stop_flag:
            wrong_cnt = 0
            for i in range(len(y)):
                if y[i] * self.sign(y, i) <= 0:
                    self.a[i] += self.lr
                    self.b += self.lr * y[i]
                    wrong_cnt += 1
            if not wrong_cnt:
                stop_flag = True
                
# 预先计算 Gram 矩阵
n = len(X)
MyGram = [[0 for i in range(n)] for j in range(n)]
for i in range(n):
    for j in range(n):
        MyGram[i][j] = np.dot(X[i], X[j])

# 训练model
model = Perceptron()
model.fit(MyGram, y)

# 重新计算 w，方便绘制图像
re_w = np.zeros(len(X[0]), dtype=np.float32)
multi_vec = model.a * y
for i in range(len(y)):
    re_w += multi_vec[i] * X[i]

# 绘制图像
x_points = np.linspace(4, 7, 20)
y_ = -(re_w[0] * x_points + model.b) / re_w[1] # 分类平面 WX + b = 0
plt.plot(x_points, y_)
plt.plot(data[:50, 0], data[:50, 1],  'bo', c='r', label='0')
plt.plot(data[50:100, 0], data[50:100, 1], 'bo', c='b', label='1')
plt.xlabel('sepal length')
plt.ylabel('sepal width')
plt.legend()
```

![Screenshot 2022-02-13 at 9.48.40 PM](/Users/cainanguan/Library/Application Support/typora-user-images/Screenshot 2022-02-13 at 9.48.40 PM.png)

可以看到取得完全相同的结果。引入对偶形式以后，训练实例仅以内积形式出现，为以后核函数引入创造了条件。

**总结：**

* 感知机采用随机梯度下降算法，算法简单易于实现。

* 如果训练集线性可分，则感知机算法能够收敛；否则可能出现震荡。
* 感知机算法由于**初始化参数**/**学习率**/**迭代顺序**不同，可能出现无穷多个解；而SVM将加入限定条件，使得解唯一。



### 3. K邻近法









